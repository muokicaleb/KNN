{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors\n",
    "Knn is a non-parametric lazy learning algorithm.\n",
    "It doesn't make any assumptions on the underlying data. The model structure is built from the data. It is a good choice in instances where there is little of no prior knowledge of the data.\n",
    "Knn is called a lazy  algorithm because it doesn't use the training points to do any generalization.\n",
    "\n",
    "A simple way to of looking at the algorithm is in KNN we classify a point based on the distance from the point to the neighbors.\n",
    "the distance can be measured in various ways depending on the data.\n",
    "Some pros to this algorithm are:\n",
    "1.It is simple\n",
    "2.Relatively accurate\n",
    "3.Versatile\n",
    "4.Doesn't need prior information\n",
    "Cons:\n",
    "1.Computationally expensive\n",
    "2.Slow\n",
    "3.sensitive to irrelevant features\n",
    "\n",
    "you can get more information about the algorithm look at\n",
    "\n",
    "https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\n",
    "\n",
    "http://www.scholarpedia.org/article/K-nearest_neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mike's Problem.\n",
    "Your friend Mike has been trying to get a girlfriend. He's been on multiple dates but they haven't been fruitful.\n",
    "You decided to use KNN to help him see if he'll like a girl based on date he collected from his previous dates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>We'll first write the entire code then explain it from the bottom up.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 691\n",
      "Test set: 308\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='smallDoses'\n",
      "Accuracy: 78.24675324675324%\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "\n",
    "def loadDataset(filename, split, trainingSet=[] , testSet=[]):\n",
    "    with open(filename,'r') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        for x in range(len(dataset)-1):\n",
    "            for y in range(3):\n",
    "                dataset [x][y] = float(dataset[x][y])\n",
    "            if random.random() < split:\n",
    "                trainingSet.append(dataset[x])\n",
    "            else:\n",
    "                testSet.append(dataset[x])\n",
    "                \n",
    "def euclideanDistance(instance1, instance2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += pow(instance1[x] - instance2[x], 2)\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "\n",
    "def getNeighbors(trainingSet, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance)-1\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = euclideanDistance(testInstance, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n",
    "\n",
    " \n",
    "    \n",
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedVotes[0][0]\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "def main():\n",
    "    #prepare data\n",
    "    trainingSet=[]\n",
    "    testSet=[]\n",
    "    split = 0.68\n",
    "    loadDataset('mike', split, trainingSet, testSet)\n",
    "    print('Train set: ' + repr(len(trainingSet)))\n",
    "    print('Test set: ' + repr(len(testSet)))\n",
    "    #generate predictions\n",
    "    predictions=[]\n",
    "    k = 3\n",
    "    for x in range(len(testSet)):\n",
    "        neighbors = getNeighbors(trainingSet, testSet[x], k)\n",
    "        result = getResponse(neighbors)\n",
    "        predictions.append(result)\n",
    "        print('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][-1]))\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print('Accuracy: ' + repr(accuracy) + '%')\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Starting from line 76 (shift+l to view line numbers in the code cell) we call the main function which starts from line 57 it takes no parameters.<br/> In the function we create two lists and a varible called split which is initialized with a value of 0.68.<br/> In KNN we split data into training data and test data . the training data does the training then we use the test data to check if the model is doing the right thing.<br/>In most cases it is advisable to use 0.7(70%) of your data to train and the 0.3(30%) of the data to test. The 2 lists and the split variable are used for this purpose<br/> In line 62 (inside the main function) We call the loadDataset function which is declared from line 6 to 16 and pass it parameters for the name of the file, split ration, trainlist and testlist </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>LoadDataset</b><br/> In this fuction we open our file 'mike' as csvfile. the file is then read and placed in a variable line. line is then converted into a list. We the enter into our first for loop. If you look at the data you'll notice that the first 3 columns are in figures so we need to convert them into floats because the system will read them as strings. In  our data we convert the 3 columns into floats so as to do operations on them. <br/>\n",
    "Next we use a random function to generate a random number if the random number is less than our split value we place it in the trainingSet if its more we place it in the testSet. When the function completes execution we go back to the main function line 63 and 64 where we print the number of entries in both sets.<br/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Next we create a list for placing the predictions and a variable k. The K is the number of neighbours we want. At line 68 we create a for loop that goes through our testSet a single entry at a time.<br/>\n",
    "Lets take the first entry as an exmple of the process.In line 69 we create a variable neighbours which is equal to the result of the getNeighbour function that takes 3 parameters the trainingSet, the specific testSet entry(entry 0 in our case) then the parameter k.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>getNeighbours</b><br/> In this function we create a list distance and a varible length which is less the length of the test set by one. \n",
    "<br/> We then enter a for loop in line 28 which iterates the length of trainSet.\n",
    "    Line 29 we create a variable and its value is the result of the euclideanDistance function. <b>euclideanDistance</b> This function takes the 3 arguments suplied and gets the distance from the test entry to to other points.You can get an explanation of how to work out euclidean distance in mathematics from www.google.com\n",
    "<br> We go back to getNeighbours line 30 where we populate our distance list with value of the training instance and the distance it is from the test instance . We then sort the distance list and create a list called neighbours. The list neighbours is then populated with the top k values from the distance list. K in our case is 3.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Going back to the main function in line 70 we create a variable result and assign it a value of getResponse function, which takes neighbor as a parameyer<br/>\n",
    "<b>getResponse</b> This function takes looks at the neighbors list then votes on which entry appears most then it becomes the getResponse return value. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In line 71 we  append our result value to the prediction list the print what we predicted and the actual value of the test instance. we then exit the for loop. <br/>\n",
    "<b>getAccuracy</b>\n",
    "Inorder to know if our model is working correctly we need to look at the accuracy of our predictions.In line 73 we declare a variable accuracy and assign it the return from getAccuracy fuction.\n",
    "The function creates a counter. the goes through the predictions and the correct value if the prediction is correct it increments the counter then divides the counter by the number of test entries and multiplies by 100 to get the percentage. The percentage is then printed out in line 74. This is how accurate our model is.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3>\n",
    "<p>Our model has a 78% accuracy.In my opinion I wouldn't advice Mike to use this model to find a mate not because our model is not accurate enough but because we can't quantify some aspects of relationships.  </p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
