{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors\n",
    "Knn is a non-parametric lazy learning algorithm.\n",
    "It doesn't make any assumptions on the underlying data. The model structure is built from the data. It is a good choice in instances where there is little of no prior knowledge of the data.\n",
    "Knn is called a lazy  algorithm because it doesn't use the training points to do any generalization.\n",
    "\n",
    "A simple way to of looking at the algorithm is in KNN we classify a point based on the distance from the point to the neighbors.\n",
    "the distance can be measured in various ways depending on the data.\n",
    "Some pros to this algorithm are:\n",
    "1.It is simple\n",
    "2.Relatively accurate\n",
    "3.Versatile\n",
    "4.Doesn't need prior information\n",
    "Cons:\n",
    "1.Computationally expensive\n",
    "2.Slow\n",
    "3.sensitive to irrelevant features\n",
    "\n",
    "you can get more information about the algorithm look at\n",
    "\n",
    "https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\n",
    "\n",
    "http://www.scholarpedia.org/article/K-nearest_neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mike's Problem.\n",
    "Your friend Mike has been trying to get a girlfriend. He's been on multiple dates but they haven't been fruitful.\n",
    "You decided to use KNN to help him see if he'll like a girl based on date he collected from his previous dates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>We'll first write the entire code then explain it from the bottom up.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 691\n",
      "Test set: 308\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='didntLike'\n",
      "> predicted='didntLike', actual='largeDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='largeDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='didntLike', actual='didntLike'\n",
      "> predicted='largeDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='smallDoses', actual='smallDoses'\n",
      "> predicted='largeDoses', actual='smallDoses'\n",
      "Accuracy: 78.24675324675324%\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "\n",
    "def loadDataset(filename, split, trainingSet=[] , testSet=[]):\n",
    "    with open(filename,'r') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        for x in range(len(dataset)-1):\n",
    "            for y in range(3):\n",
    "                dataset [x][y] = float(dataset[x][y])\n",
    "            if random.random() < split:\n",
    "                trainingSet.append(dataset[x])\n",
    "            else:\n",
    "                testSet.append(dataset[x])\n",
    "                \n",
    "def euclideanDistance(instance1, instance2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += pow(instance1[x] - instance2[x], 2)\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "\n",
    "def getNeighbors(trainingSet, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance)-1\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = euclideanDistance(testInstance, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n",
    "\n",
    " \n",
    "    \n",
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedVotes[0][0]\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "def main():\n",
    "    #prepare data\n",
    "    trainingSet=[]\n",
    "    testSet=[]\n",
    "    split = 0.68\n",
    "    loadDataset('mike', split, trainingSet, testSet)\n",
    "    print('Train set: ' + repr(len(trainingSet)))\n",
    "    print('Test set: ' + repr(len(testSet)))\n",
    "    #generate predictions\n",
    "    predictions=[]\n",
    "    k = 3\n",
    "    for x in range(len(testSet)):\n",
    "        neighbors = getNeighbors(trainingSet, testSet[x], k)\n",
    "        result = getResponse(neighbors)\n",
    "        predictions.append(result)\n",
    "        print('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][-1]))\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print('Accuracy: ' + repr(accuracy) + '%')\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Starting from line 76 (shift+l to view line numbers in the code cell) we call the main function which starts from line 57 it takes no parameters.<br/> In the function we create two lists and a varible called split which is initialized with a value of 0.68.<br/> In KNN we split data into training data and test data . the training data does the training then we use the test data to check if the model is doing the right thing.<br/>In most cases it is advisable to use 0.7(70%) of your data to train and the 0.3(30%) of the data to test. The 2 lists and the split variable are used for this purpose<br/> In line 62 (inside the main function) We call the loadDataset function which is declared from line 6 to 16 and pass it parameters for the name of the file, split ration, trainlist and testlist </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>LoadDataset</b><br/> In this fuction we open our file 'mike' as csvfile. the file is then read and placed in a variable line. line is then converted into a list. We the enter into our first for loop. If you look at the data you'll notice that the first 3 columns are in figures so we need to convert them into floats because the system will read them as strings. In  our data we convert the 3 columns into floats so as to do operations on them. <br/>\n",
    "Next we use a random function to generate a random number if the random number is less than our split value we place it in the trainingSet if its more we place it in the testSet. When the function completes execution we go back to the main function line 63 and 64 where we print the number of entries in both sets.<br/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Next we create a list for placing the predictions and a variable k. The K is the number of neighbours we want. At line 68 we create a for loop that goes through our testSet a single entry at a time.<br/>\n",
    "Lets take the first entry as an exmple of the process.In line 69 we create a variable neighbours which is equal to the result of the getNeighbour function that takes 3 parameters the trainingSet, the specific testSet entry(entry 0 in our case) then the parameter k.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>getNeighbours</b><br/> In this function we create a list distance and a varible length which is less the length of the test set by one. \n",
    "<br/> We then enter a for loop in line 28 which iterates the length of trainSet.\n",
    "    Line 29 we create a variable and its value is the result of the euclideanDistance function.<b>euclideanDistance</b>This function takes the 3 arguments suplied and gets the distance from the test entry to to other points.You can get an explanation of how to work out euclidean distance in mathematics from www.google.com\n",
    "<br> We go back to getNeighbours line 30 where we populate our distance list with value of the training instance and the distance it is from the test instance . We then sort the distance list and create a list called neighbours. The list neighbours is then populated with the top k values from the distance list. K in our case is 3.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
